{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM + Catboost on tabular data\n",
    "\n",
    "Tabular data LGBM + Catboost strategy found from here: \n",
    "https://www.kaggle.com/code/vyacheslavbolotin/lightgbm-catboost-with-new-features#Competition-Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import catboost as cb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xusha\\AppData\\Local\\Temp\\ipykernel_773680\\568092388.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(\"../data/train-metadata.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/train-metadata.csv\")\n",
    "df_test = pd.read_csv(\"../data/test-metadata.csv\")\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # New features to try...\n",
    "    df[\"lesion_size_ratio\"]              = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    df[\"lesion_shape_index\"]             = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
    "    df[\"hue_contrast\"]                   = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "    df[\"luminance_contrast\"]             = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "    df[\"lesion_color_difference\"]        = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
    "    df[\"border_complexity\"]              = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"color_uniformity\"]               = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "    \n",
    "    df[\"3d_position_distance\"]           = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n",
    "    df[\"perimeter_to_area_ratio\"]        = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    df[\"area_to_perimeter_ratio\"]        = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"lesion_visibility_score\"]        = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    df[\"combined_anatomical_site\"]       = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
    "    df[\"symmetry_border_consistency\"]    = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    df[\"consistency_symmetry_border\"]    = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] / (df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"])\n",
    "    \n",
    "    df[\"color_consistency\"]              = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    df[\"consistency_color\"]              = df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] / (df[\"tbp_lv_stdL\"] + df[\"tbp_lv_Lext\"])\n",
    "    df[\"size_age_interaction\"]           = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    df[\"hue_color_std_interaction\"]      = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"lesion_severity_index\"]          = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    df[\"shape_complexity_index\"]         = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    df[\"color_contrast_index\"]           = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
    "    \n",
    "    df[\"log_lesion_area\"]                = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"normalized_lesion_size\"]         = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    df[\"mean_hue_difference\"]            = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    df[\"std_dev_contrast\"]               = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
    "    df[\"color_shape_composite_index\"]    = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    df[\"3d_lesion_orientation\"]          = np.arctan2(df_train[\"tbp_lv_y\"], df_train[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"]       = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "    \n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"comprehensive_lesion_index\"]     = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "    df[\"color_variance_ratio\"]           = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "    df[\"border_color_interaction\"]       = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    df[\"size_color_contrast_ratio\"]      = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "    df[\"color_asymmetry_index\"]          = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    \n",
    "    df[\"3d_volume_approximation\"]        = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    df[\"color_range\"]                    = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n",
    "    df[\"shape_color_consistency\"]        = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"border_length_ratio\"]            = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n",
    "    df[\"age_size_symmetry_index\"]        = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"index_age_size_symmetry\"]        = df[\"age_approx\"] * df[\"tbp_lv_areaMM2\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    # Until here..\n",
    "    # df['np1']                           = np.sqrt(df[\"tbp_lv_deltaB\"]**2 + df[\"tbp_lv_deltaL\"]**2 + df[\"tbp_lv_deltaLB\"]**2) / (df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLB\"])\n",
    "    # df['np2']                           = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaLB\"]) / np.sqrt(df[\"tbp_lv_deltaA\"]**2 + df[\"tbp_lv_deltaLB\"]**2)\n",
    "    # df['np3']                           = ?\n",
    "    # ...\n",
    "    # df['npn']                           = ?\n",
    "    \n",
    "    new_num_cols = [\n",
    "        \"lesion_size_ratio\",             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
    "        \"lesion_shape_index\",            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
    "        \"hue_contrast\",                  # tbp_lv_H                - tbp_lv_Hext              abs\n",
    "        \"luminance_contrast\",            # tbp_lv_L                - tbp_lv_Lext              abs\n",
    "        \"lesion_color_difference\",       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n",
    "        \"border_complexity\",             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
    "        \"color_uniformity\",              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
    "        \n",
    "        \"3d_position_distance\",          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
    "        \"perimeter_to_area_ratio\",       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
    "        \"area_to_perimeter_ratio\",       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "        \"lesion_visibility_score\",       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
    "        # \"combined_anatomical_site\"      # anatom_site_general     + \"_\" + tbp_lv_location ! categorical feature\n",
    "        \"symmetry_border_consistency\",   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
    "        \"consistency_symmetry_border\",   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "        \n",
    "        \"color_consistency\",             # tbp_lv_stdL             / tbp_lv_Lext\n",
    "        \"consistency_color\",             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "        \"size_age_interaction\",          # clin_size_long_diam_mm  * age_approx\n",
    "        \"hue_color_std_interaction\",     # tbp_lv_H                * tbp_lv_color_std_mean\n",
    "        \"lesion_severity_index\",         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
    "        \"shape_complexity_index\",        # border_complexity       + lesion_shape_index\n",
    "        \"color_contrast_index\",          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
    "        \n",
    "        \"log_lesion_area\",               # tbp_lv_areaMM2          + 1  np.log\n",
    "        \"normalized_lesion_size\",        # clin_size_long_diam_mm  / age_approx\n",
    "        \"mean_hue_difference\",           # tbp_lv_H                + tbp_lv_Hext    / 2\n",
    "        \"std_dev_contrast\",              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
    "        \"color_shape_composite_index\",   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
    "        \"3d_lesion_orientation\",         # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
    "        \"overall_color_difference\",      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
    "        \n",
    "        \"symmetry_perimeter_interaction\",# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
    "        \"comprehensive_lesion_index\",    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
    "        \"color_variance_ratio\",          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
    "        \"border_color_interaction\",      # tbp_lv_norm_border      * tbp_lv_norm_color\n",
    "        \"size_color_contrast_ratio\",     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
    "        \"age_normalized_nevi_confidence\",# tbp_lv_nevi_confidence  / age_approx\n",
    "        \"color_asymmetry_index\",         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
    "        \n",
    "        \"3d_volume_approximation\",       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
    "        \"color_range\",                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
    "        \"shape_color_consistency\",       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
    "        \"border_length_ratio\",           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
    "        \"age_size_symmetry_index\",       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
    "         #\"index_age_size_symmetry\",      # age_approx              * sqrt(tbp_lv_areaMM2 * tbp_lv_symm_2axis)\n",
    "        \"index_age_size_symmetry\",       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "         # Until here..\n",
    "         # 'np1',                         # in case of a positive manifestation\n",
    "         # 'np2',                         # in case of a positive manifestation\n",
    "         # 'np3'                          # = ?\n",
    "         # ...\n",
    "         # 'npn'                          # = ?\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # The following features have been added:\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    \n",
    "    # \"area_to_perimeter_ratio\",       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
    "    # \"consistency_symmetry_border\",   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
    "    # \"consistency_color\",             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
    "    # \"index_age_size_symmetry\",       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    \n",
    "    # They were added all at once and by instinct.\n",
    "    # I think this is not quite right, it would be better to add them one by one\n",
    "    # and then visually look(even better is a machine gun) at the result\n",
    "     \n",
    "    # Working only with the taboo values of expert Andreas Bisi showed that it is possible to work \n",
    "    # with a smaller number of functions available to us, \n",
    "    # so in the next versions we will try to remove some functions rather than add them.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    new_cat_cols = [\"combined_anatomical_site\"]\n",
    "    \n",
    "    return df, new_num_cols, new_cat_cols\n",
    "\n",
    "\n",
    "num_cols = [\n",
    "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
    "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
    "    'tbp_lv_A',                          # A inside  lesion.+\n",
    "    'tbp_lv_Aext',                       # A outside lesion.+\n",
    "    'tbp_lv_B',                          # B inside  lesion.+\n",
    "    'tbp_lv_Bext',                       # B outside lesion.+ \n",
    "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
    "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
    "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
    "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
    "    'tbp_lv_L',                          # L inside lesion.+\n",
    "    'tbp_lv_Lext',                       # L outside lesion.+\n",
    "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
    "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
    "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
    "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
    "    'tbp_lv_deltaLB',                    #\n",
    "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
    "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
    "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
    "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
    "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
    "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
    "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
    "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
    "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
    "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
    "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
    "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
    "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
    "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
    "]\n",
    "\n",
    "df_train[num_cols] = df_train[num_cols].fillna(df_train[num_cols].median())\n",
    "df_test [num_cols] = df_test [num_cols].fillna(df_train[num_cols].median())\n",
    "\n",
    "df_train, new_num_cols, new_cat_cols = feature_engineering(df_train.copy())\n",
    "df_test, _, _                        = feature_engineering(df_test.copy())\n",
    "\n",
    "num_cols += new_num_cols\n",
    "\n",
    "# anatom_site_general\n",
    "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"] + new_cat_cols\n",
    "train_cols = num_cols + cat_cols\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_eff = pd.read_csv(\"/kaggle/input/isic-inference-effnetv1b0-for-training-data/train_effnetv1b0.csv\")\n",
    "# df_eff = df_eff[[\"target_effnetv1b0\"]]\n",
    "\n",
    "# df_nex = pd.read_csv(\"/kaggle/input/nextvit/train_effnetv1b0.csv\")\n",
    "# df_nex = df_nex[[\"target_effnetv1b0\"]]\n",
    "# df_sel = pd.read_csv(\"/kaggle/input/selecsls42b-in1k-drop/train_effnetv1b0.csv\")\n",
    "# df_sel = df_sel[[\"target_effnetv1b0\"]]\n",
    "\n",
    "# df_train[\"target_nexnetv1b0\"] = df_nex[\"target_effnetv1b0\"]\n",
    "# df_train[\"target_selnetv1b0\"] = df_sel[\"target_effnetv1b0\"]\n",
    "\n",
    "\n",
    "# df_image_3 = pd.read_csv(\"/kaggle/input/isic-2024-pl-submission-script-and-preds/train_preds.csv\")\n",
    "\n",
    "# df_train[\"target_effnetv1b0\"] = df_eff[\"target_effnetv1b0\"]\n",
    "# df_train[\"target_3\"] = df_image_3[\"pred\"]\n",
    "\n",
    "# train_cols += [\"target_3\",\"target_nexnetv1b0\",\"target_effnetv1b0\",\"target_selnetv1b0\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~\n",
    "# approximately the same FE does not give anything yet the correct \n",
    "# one asks to add one or more parallel lines\n",
    "# ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~ ~ + ~\n",
    "\n",
    "\n",
    "category_encoder = OrdinalEncoder(\n",
    "    categories='auto',\n",
    "    dtype=int,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-2,\n",
    "    encoded_missing_value=-1,\n",
    ")\n",
    "\n",
    "X_cat = category_encoder.fit_transform(df_train[cat_cols])\n",
    "for c, cat_col in enumerate(cat_cols):\n",
    "    df_train[cat_col] = X_cat[:, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "\n",
    "gkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)  \n",
    "\n",
    "df_train[\"fold\"] = -1\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(gkf.split(df_train, df_train[\"target\"], groups=df_train[\"patient_id\"])):\n",
    "    df_train.loc[val_idx, \"fold\"] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitive Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "def custom_lgbm_metric(y_true, y_hat):\n",
    "    # TODO: Refactor with the above.\n",
    "    min_tpr = 0.80\n",
    "    v_gt = abs(y_true-1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return \"pauc80\", partial_auc, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Model\n",
    "\n",
    "With found optimal parameters for model fitting from Kaggle notebook linked earlier ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - Partial AUC Score: 0.15745\n",
      "fold: 1 - Partial AUC Score: 0.16689\n",
      "fold: 2 - Partial AUC Score: 0.17378\n",
      "fold: 3 - Partial AUC Score: 0.13681\n",
      "fold: 4 - Partial AUC Score: 0.15526\n"
     ]
    }
   ],
   "source": [
    "new_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_estimators\": 200,\n",
    "    'learning_rate': 0.05,    \n",
    "    'lambda_l1': 0.0004681884533249742, \n",
    "    'lambda_l2': 8.765240856362274, \n",
    "    'num_leaves': 136, \n",
    "    'feature_fraction': 0.5392005444882538, \n",
    "    'bagging_fraction': 0.9577412548866563, \n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 60,\n",
    "    \"device\": \"gpu\"\n",
    "}\n",
    "lgb_scores = []\n",
    "lgb_models = []\n",
    "oof_df = pd.DataFrame()\n",
    "for fold in range(N_SPLITS):\n",
    "    _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "    _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "    model = lgb.LGBMClassifier(**new_params)\n",
    "    # model = VotingClassifier([(f\"lgb_{i}\", lgb.LGBMClassifier(random_state=i, **new_params)) for i in range(7)], voting=\"soft\")\n",
    "    model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "    preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "    score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "    print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
    "    lgb_models.append(model)\n",
    "    oof_single = _df_valid[[\"isic_id\", \"target\"]].copy()\n",
    "    oof_single[\"pred\"] = preds\n",
    "    oof_df = pd.concat([oof_df, oof_single])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Score: 0.15604\n"
     ]
    }
   ],
   "source": [
    "lgbm_score = comp_score(oof_df[\"target\"], oof_df[\"pred\"], \"\")\n",
    "print(f\"LGBM Score: {lgbm_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1c212a5acb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model for ensembling later\n",
    "model.booster_.save_model(\"./output/lightgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Model\n",
    "\n",
    "With found optimal parameters for model fitting from Kaggle notebook linked earlier ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - Partial AUC Score: 0.14568\n",
      "fold: 1 - Partial AUC Score: 0.15622\n",
      "fold: 2 - Partial AUC Score: 0.18395\n",
      "fold: 3 - Partial AUC Score: 0.14203\n",
      "fold: 4 - Partial AUC Score: 0.15104\n"
     ]
    }
   ],
   "source": [
    "cb_params = {\n",
    "    'objective': 'Logloss',\n",
    "    # \"random_state\": 42,\n",
    "    # \"colsample_bylevel\": 0.3, # 0.01, 0.1\n",
    "    \"iterations\": 400,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"cat_features\": cat_cols,\n",
    "    \"max_depth\": 8,\n",
    "    \"l2_leaf_reg\": 5,\n",
    "    \"task_type\": \"GPU\",\n",
    "    # \"scale_pos_weight\": 2,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "cb_scores = []\n",
    "cb_models = []\n",
    "for fold in range(N_SPLITS):\n",
    "    _df_train = df_train[df_train[\"fold\"] != fold].reset_index(drop=True)\n",
    "    _df_valid = df_train[df_train[\"fold\"] == fold].reset_index(drop=True)\n",
    "    model = cb.CatBoostClassifier(**cb_params)\n",
    "    # model = VotingClassifier([(f\"cb_{i}\", cb.CatBoostClassifier(random_state=i, **cb_params)) for i in range(3)], voting=\"soft\")\n",
    "    # eval_set=(_df_valid[train_cols], _df_valid[\"target\"]), early_stopping_rounds=50\n",
    "    model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "    preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "    score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n",
    "    print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n",
    "    cb_scores.append(score)\n",
    "    cb_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Score: 0.15579\n"
     ]
    }
   ],
   "source": [
    "cb_score = np.mean(cb_scores)\n",
    "print(f\"CatBoost Score: {cb_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for ensembling later\n",
    "model.save_model(\"./output/catboost_model.cbm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6600_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
