{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Attempt for ISIC 2024 - Skin Cancer Detection with 3D-TBP\n",
    "\n",
    "Present issue is the massive imbalance in the dataset of positives compared to negatives. To address this issue, I will utilize a custom sampler object called `ImbalancedDatasetSampler` when initiating DataLoader objects.\n",
    "\n",
    "Another step to increase the effectiveness of CNN on binary classification of skin cancer on the image dataset is using an ensemble of CNN's which is commonly known to increase overall performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torcheval.metrics.functional import binary_auroc\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "import h5py\n",
    "import io\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# cuda gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"img_size\": 336,\n",
    "    \"train_batch_size\": 150,\n",
    "    \"valid_batch_size\": 200,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": device,\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set seed and \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "ROOT_DIR = \"../data\"\n",
    "TRAIN_CSV = f\"{ROOT_DIR}/train-metadata.csv\"\n",
    "TRAIN_HDF = f\"{ROOT_DIR}/train-image.hdf5\"\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "SAMPLE = f'{ROOT_DIR}/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data\n",
    "\n",
    "Code to read in data is from Eren's notebook: https://www.kaggle.com/code/metlnfoor/resnet34-removing-hair-under-sampling/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(TRAIN_CSV, low_memory=False)\n",
    "test_metadata = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_hdf5(file_path):\n",
    "    images = {}\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            for key in tqdm(file.keys(), desc=\"Reading Files\"):\n",
    "                try:\n",
    "                    image_data = file[key][()]\n",
    "                    image = Image.open(io.BytesIO(image_data))\n",
    "                    images[key] = image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error! from {key}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occured while reading files : {e}\")\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files: 100%|██████████| 401059/401059 [02:18<00:00, 2889.36it/s]\n",
      "Reading Files: 100%|██████████| 3/3 [00:00<00:00, 1504.41it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = read_images_from_hdf5(TRAIN_HDF)\n",
    "test_images = read_images_from_hdf5(TEST_HDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Hair function and Skin Tone standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function from https://www.kaggle.com/competitions/isic-2024-challenge/discussion/519735\n",
    "def remove_hair(image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "        blackhat = cv2.morphologyEx(gray,cv2.MORPH_BLACKHAT,kernel)\n",
    "\n",
    "        _, thresh = cv2.threshold(blackhat, 10 ,255, cv2.THRESH_BINARY)\n",
    "        inpainted_image = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "        return inpainted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_stand(image):\n",
    "    \n",
    "\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISIC_2024(Dataset):\n",
    "    def __init__(self,pil_images,metadata,transform=None,test=False):\n",
    "        self.pil_images = pil_images\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "        self.test= test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    # This function from https://www.kaggle.com/competitions/isic-2024-challenge/discussion/519735\n",
    "    def remove_hair(image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "        blackhat = cv2.morphologyEx(gray,cv2.MORPH_BLACKHAT,kernel)\n",
    "\n",
    "        _, thresh = cv2.threshold(blackhat, 10 ,255, cv2.THRESH_BINARY)\n",
    "        inpainted_image = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "        return inpainted_image\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        isic_id = self.metadata.iloc[idx,0]\n",
    "        cleaned_image = remove_hair(np.array(self.pil_images[isic_id]))\n",
    "        image = Image.fromarray(cleaned_image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.test:\n",
    "            return image\n",
    "        label = self.metadata.iloc[idx,-1]\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define DataLoader Transforms\n",
    "\"\"\"\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "                mean=[0.4815, 0.4578, 0.4082], \n",
    "                std=[0.2686, 0.2613, 0.2758], \n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()\n",
    "    ], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "        A.Normalize(\n",
    "                mean=[0.4815, 0.4578, 0.4082], \n",
    "                std=[0.2686, 0.2613, 0.2758], \n",
    "                max_pixel_value=255.0,\n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2(),\n",
    "        ], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(df, df_pseudo):\n",
    "    \n",
    "    train_dataset = ISICDataset_for_Train(df, TRAIN_HDF, df_pseudo, TEST_HDF, transforms=data_transforms[\"train\"])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model 1: ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.resnet152(weights = models.ResNet152_Weights.IMAGENET1K_V1)\n",
    "model1.fc = nn.Linear(model1.fc.in_features, 2) #change to 200 outputs for the 200 classes\n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=CONFIG['learning_rate'], \n",
    "                       weight_decay=CONFIG['weight_decay'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "scheduler = fetch_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Val Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc  = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        auroc = binary_auroc(input=outputs.squeeze(), target=targets).item()\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Train_Auroc=epoch_auroc,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_auroc\n",
    "\n",
    "\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for _, data in bar:        \n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        auroc = binary_auroc(input=outputs.squeeze(), target=targets).item()\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, Valid_Auroc=epoch_auroc,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_auroc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(df_test, file_test_hdf, model):\n",
    "    model.eval();\n",
    "    test_dataset = ISICDataset(df_test, file_test_hdf, transforms=data_transforms[\"valid\"])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'],\n",
    "                               shuffle=False, pin_memory=True)\n",
    "    \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "        for _, data in bar:        \n",
    "            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)        \n",
    "            outputs = model(images)\n",
    "            preds.append( outputs.detach().cpu().numpy() )\n",
    "    preds = np.concatenate(preds).flatten()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auroc = -np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        # Inference test data\n",
    "        df_test = pd.read_csv(TEST_CSV)\n",
    "        df_test[\"target\"] = 0 # dummy\n",
    "        df_test[\"target\"] = inference(df_test, TEST_HDF, model)\n",
    "        \n",
    "        # create training dataset\n",
    "        train_loader = prepare_loaders(df, df_test, fold=CONFIG[\"fold\"])\n",
    "        del df_test\n",
    "        gc.collect()\n",
    "        \n",
    "        # train (1epoch)\n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        del train_loader\n",
    "        gc.collect()\n",
    "        \n",
    "        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                        epoch=epoch)\n",
    "        del valid_loader\n",
    "        gc.collect()\n",
    "        \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train AUROC'].append(train_epoch_auroc)\n",
    "        history['Valid AUROC'].append(val_epoch_auroc)\n",
    "        history['lr'].append( scheduler.get_lr()[0] )\n",
    "        \n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = \"model_epoch{:.0f}.bin\".format(epoch)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "        # deep copy the model\n",
    "        if best_epoch_auroc <= val_epoch_auroc:\n",
    "           print(f\"Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n",
    "           best_epoch_auroc = val_epoch_auroc\n",
    "           best_model_wts = copy.deepcopy(model.state_dict())\n",
    "           PATH = \"AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(val_epoch_auroc, val_epoch_loss, epoch)\n",
    "           torch.save(model.state_dict(), PATH)\n",
    "           # Save a model file from the current directory\n",
    "           print(f\"Current model Saved\")\n",
    "            \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA GeForce RTX 4060 Ti\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (6) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1, history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, optimizer, scheduler, device, num_epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(TEST_CSV)\n\u001b[0;32m     13\u001b[0m df_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# dummy\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m inference(df_test, TEST_HDF, model)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# create training dataset\u001b[39;00m\n\u001b[0;32m     17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m prepare_loaders(df, df_test, fold\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\xusha\\anaconda3\\envs\\dsan6600_2\\lib\\site-packages\\pandas\\core\\frame.py:4299\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4298\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4299\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xusha\\anaconda3\\envs\\dsan6600_2\\lib\\site-packages\\pandas\\core\\frame.py:4512\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4503\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4504\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4505\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4510\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4511\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4512\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4515\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4516\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4517\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4518\u001b[0m     ):\n\u001b[0;32m   4519\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4520\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\xusha\\anaconda3\\envs\\dsan6600_2\\lib\\site-packages\\pandas\\core\\frame.py:5253\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5253\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5254\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5256\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5257\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xusha\\anaconda3\\envs\\dsan6600_2\\lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (6) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "model1, history = run_training(model1, optimizer, scheduler,\n",
    "                              device=device,\n",
    "                              num_epochs=CONFIG['epochs'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6600_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
