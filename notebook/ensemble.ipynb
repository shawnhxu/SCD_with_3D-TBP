{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble CNNs + CatBoost + LGBM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to find in this notebook:\n",
    "- Reload all trained models here.\n",
    "- Load in tabular as well as image data in test dataset.\n",
    "- Setup ensemble model.\n",
    "- Evaluate models with appropriate data.\n",
    "- Create submission.csv for Kaggle submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "ROOT_DIR = \"../data\"\n",
    "TRAIN_CSV = f\"{ROOT_DIR}/train-metadata.csv\"\n",
    "TRAIN_HDF = f\"{ROOT_DIR}/train-image.hdf5\"\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "SAMPLE = f'{ROOT_DIR}/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"img_size\": 224,\n",
    "    \"train_batch_size\": 150,\n",
    "    \"valid_batch_size\": 200,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": device,\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competitive Score metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "def custom_lgbm_metric(y_true, y_hat):\n",
    "    # TODO: Refactor with the above.\n",
    "    min_tpr = 0.80\n",
    "    v_gt = abs(y_true-1)\n",
    "    v_pred = np.array([1.0 - x for x in y_hat])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return \"pauc80\", partial_auc, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init CNN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RESNET152\n",
    "\"\"\"\n",
    "\n",
    "class CustomResNet152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet152, self).__init__()\n",
    "        # Load a pre-trained ResNet-152 model\n",
    "        self.base_model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # remove last fully connected layer for our purposes\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-2])\n",
    "\n",
    "        # Classifier that includes flattening the feature map and linear layer for class prediction\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 1),  # output single value for prob calculation\n",
    "            nn.Sigmoid()  # sigmoid activation for probability\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # extract features\n",
    "        x = self.features(x)\n",
    "        # classify features\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "model1 = CustomResNet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RESNET50\n",
    "\"\"\"\n",
    "\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        # Load a pre-trained ResNet-152 model\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # remove last fully connected layer for our purposes\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-2])\n",
    "\n",
    "        # Classifier that includes flattening the feature map and linear layer for class prediction\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 1),  # output single value for prob calculation\n",
    "            nn.Sigmoid()  # sigmoid activation for probability\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # extract features\n",
    "        x = self.features(x)\n",
    "        # classify features\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "model2 = CustomResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MobileNetV2\n",
    "\"\"\"\n",
    "\n",
    "class CustomMobileNetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMobileNetV2, self).__init__()\n",
    "        self.base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.features = self.base_model.features\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "model3 = CustomMobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MNASNet-1.0\n",
    "\"\"\"\n",
    "\n",
    "class CustomMNASNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMNASNet, self).__init__()\n",
    "        self.base_model = models.mnasnet1_0(weights=models.MNASNet1_0_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.features = self.base_model.layers\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "model4 = CustomMNASNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EfficientNetB4\n",
    "\"\"\"\n",
    "\n",
    "class CustomEfficientNetB4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomEfficientNetB4, self).__init__()\n",
    "        self.base_model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4), \n",
    "            nn.Linear(self.base_model.classifier[1].in_features, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.base_model(x)\n",
    "        return output\n",
    "    \n",
    "model5 = CustomEfficientNetB4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DenseNet121\n",
    "\"\"\"\n",
    "\n",
    "class CustomDenseNet121(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNet121, self).__init__()\n",
    "        self.base_model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 1), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.base_model(x)\n",
    "        return output\n",
    "\n",
    "model6 = CustomDenseNet121()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNNs in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('./output/res152_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model2.load_state_dict(torch.load('./output/res50_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model3.load_state_dict(torch.load('./output/mobileV2_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model4.load_state_dict(torch.load('./output/mnas1_0_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model5.load_state_dict(torch.load('./output/effB4_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model6.load_state_dict(torch.load('./output/Dense121_ISIC_best.pth', map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CatBoost and LGBM in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x157eb61bb80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Catboost\n",
    "\"\"\"\n",
    "\n",
    "model7 = CatBoostClassifier()\n",
    "model7.load_model(\"./output/catboost_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LGBM\n",
    "\"\"\"\n",
    "\n",
    "model8 = lgb.Booster(model_file=\"./output/lightgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinput data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files: 100%|██████████| 3/3 [00:00<00:00, 170.74it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import just the testing dataset\n",
    "\"\"\"\n",
    "\n",
    "def read_images_from_hdf5(file_path):\n",
    "    images = {}\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            for key in tqdm(file.keys(), desc=\"Reading Files\"):\n",
    "                try:\n",
    "                    image_data = file[key][()]\n",
    "                    image = Image.open(io.BytesIO(image_data))\n",
    "                    images[key] = image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error! from {key}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occured while reading files : {e}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "test_images = read_images_from_hdf5(TEST_HDF)\n",
    "test_metadata = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import test image dataloaders for CNN evaluation\n",
    "\"\"\"\n",
    "\n",
    "def remove_hair(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    blackhat = cv2.morphologyEx(gray,cv2.MORPH_BLACKHAT,kernel)\n",
    "\n",
    "    _, thresh = cv2.threshold(blackhat, 10 ,255, cv2.THRESH_BINARY)\n",
    "    inpainted_image = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "    return inpainted_image\n",
    "\n",
    "\n",
    "class ISIC_2024(Dataset):\n",
    "    def __init__(self,pil_images,metadata,transform=None,test=False):\n",
    "        self.pil_images = pil_images\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "        self.test= test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    # This function from https://www.kaggle.com/competitions/isic-2024-challenge/discussion/519735\n",
    "    def remove_hair(image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "        blackhat = cv2.morphologyEx(gray,cv2.MORPH_BLACKHAT,kernel)\n",
    "\n",
    "        _, thresh = cv2.threshold(blackhat, 10 ,255, cv2.THRESH_BINARY)\n",
    "        inpainted_image = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "        return inpainted_image\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        isic_id = self.metadata.iloc[idx,0]\n",
    "        cleaned_image = remove_hair(np.array(self.pil_images[isic_id]))\n",
    "        image = Image.fromarray(cleaned_image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.test:\n",
    "            return image, isic_id\n",
    "        label = self.metadata.iloc[idx,-1]\n",
    "        return image,label,isic_id\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "     transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # commonly used mean and std calculated from ImageNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ISIC_2024(test_images, test_metadata, transform = test_transforms, test = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0015657', 'ISIC_0015729', 'ISIC_0015740']\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    # Check the length of the batch\n",
    "    \n",
    "    # Adjust based on what your dataset returns\n",
    "    if len(batch) == 2:\n",
    "        images, ids = batch\n",
    "    elif len(batch) == 3:\n",
    "        images, ids, labels = batch  # Assuming the third element is the label\n",
    "    # Add more conditions if necessary\n",
    "    \n",
    "    # Use the images and ids as needed\n",
    "    print(ids)\n",
    "    break  # Just to check one iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0015657', 'ISIC_0015729', 'ISIC_0015740']\n"
     ]
    }
   ],
   "source": [
    "for images, ids in test_loader:\n",
    "    print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "\n",
    "There are 8 models to ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):   \n",
    "    def __init__(self, model1, model2, model3, model4, model5, model6, model7, model8):\n",
    "        super().__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        self.model5 = model5\n",
    "        self.model6 = model6\n",
    "        self.model7 = model7\n",
    "        self.model8 = model8\n",
    "        self.classifier = nn.Linear(____)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x)\n",
    "        x2 = self.model2(x)\n",
    "        x3 = self.model3(x)\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "    \n",
    "ensemble_model = EnsembleModel(model_densenet161, model_resnet152, model_vgg19_bn)\n",
    "\n",
    "for param in ensemble_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in ensemble_model.classifier.parameters():\n",
    "    param.requires_grad = True    \n",
    "\n",
    "ensemble_model = ensemble_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cnn(model, dataloader, device):\n",
    "\n",
    "    #init eval mode\n",
    "    model.eval()\n",
    "    #init running loss, correct preds, and total correct preds for each epoch\n",
    "    epoch_total_loss = 0.0\n",
    "    epoch_correct_preds = 0\n",
    "    epoch_total_preds = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for data, target in tqdm(dataloader, desc=\"Eval Loop\"):\n",
    "        \n",
    "        #init data and target into cuda\n",
    "        data = data.to(device)\n",
    "        target = target.to(device).float()\n",
    "\n",
    "        #predict using input data\n",
    "        curr_pred = model(data)\n",
    "\n",
    "        #change the shape of target to match prediction\n",
    "        target = target.view(curr_pred.size())\n",
    "        \n",
    "        _, predicted = torch.max(curr_pred, 1)\n",
    "\n",
    "        #get the number of correct preds and total preds\n",
    "        epoch_correct_preds += (predicted == target).sum().item()\n",
    "        epoch_total_preds += target.size(0)\n",
    "\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    eval_avg_loss = epoch_total_loss / len(dataloader.dataset)\n",
    "    eval_auroc = binary_auroc(input=curr_pred.squeeze(), target=target.squeeze()).item()\n",
    "    \n",
    "\n",
    "    return eval_avg_loss, eval_auroc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6600_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
