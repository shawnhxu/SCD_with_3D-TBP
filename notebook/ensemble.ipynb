{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble CNNs + CatBoost + LGBM models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "ROOT_DIR = \"../data\"\n",
    "TRAIN_CSV = f\"{ROOT_DIR}/train-metadata.csv\"\n",
    "TRAIN_HDF = f\"{ROOT_DIR}/train-image.hdf5\"\n",
    "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
    "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
    "SAMPLE = f'{ROOT_DIR}/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"img_size\": 224,\n",
    "    \"train_batch_size\": 150,\n",
    "    \"valid_batch_size\": 200,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"fold\" : 0,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"device\": device,\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init CNN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RESNET152\n",
    "\"\"\"\n",
    "\n",
    "class CustomResNet152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet152, self).__init__()\n",
    "        # Load a pre-trained ResNet-152 model\n",
    "        self.base_model = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # remove last fully connected layer for our purposes\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-2])\n",
    "\n",
    "        # Classifier that includes flattening the feature map and linear layer for class prediction\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 1),  # output single value for prob calculation\n",
    "            nn.Sigmoid()  # sigmoid activation for probability\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # extract features\n",
    "        x = self.features(x)\n",
    "        # classify features\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "model1 = CustomResNet152()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RESNET50\n",
    "\"\"\"\n",
    "\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        # Load a pre-trained ResNet-152 model\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # remove last fully connected layer for our purposes\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-2])\n",
    "\n",
    "        # Classifier that includes flattening the feature map and linear layer for class prediction\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 1),  # output single value for prob calculation\n",
    "            nn.Sigmoid()  # sigmoid activation for probability\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # extract features\n",
    "        x = self.features(x)\n",
    "        # classify features\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "model2 = CustomResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MobileNetV2\n",
    "\"\"\"\n",
    "\n",
    "class CustomMobileNetV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMobileNetV2, self).__init__()\n",
    "        self.base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.features = self.base_model.features\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n",
    "model3 = CustomMobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MNASNet-1.0\n",
    "\"\"\"\n",
    "\n",
    "class CustomMNASNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMNASNet, self).__init__()\n",
    "        self.base_model = models.mnasnet1_0(weights=models.MNASNet1_0_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.features = self.base_model.layers\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "    \n",
    "model4 = CustomMNASNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EfficientNetB4\n",
    "\"\"\"\n",
    "\n",
    "class CustomEfficientNetB4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomEfficientNetB4, self).__init__()\n",
    "        self.base_model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4), \n",
    "            nn.Linear(self.base_model.classifier[1].in_features, 1),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.base_model(x)\n",
    "        return output\n",
    "    \n",
    "model5 = CustomEfficientNetB4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DenseNet121\n",
    "\"\"\"\n",
    "\n",
    "class CustomDenseNet121(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNet121, self).__init__()\n",
    "        self.base_model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 1), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.base_model(x)\n",
    "        return output\n",
    "\n",
    "model6 = CustomDenseNet121()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNNs in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('./output/res152_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model2.load_state_dict(torch.load('./output/res50_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model3.load_state_dict(torch.load('./output/mobileV2_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model4.load_state_dict(torch.load('./output/mnas1_0_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model5.load_state_dict(torch.load('./output/effB4_ISIC_best.pth', map_location=torch.device('cuda')))\n",
    "model6.load_state_dict(torch.load('./output/Dense121_ISIC_best.pth', map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CatBoost and LGBM in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x262b92bfd00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Catboost\n",
    "\"\"\"\n",
    "\n",
    "model7 = CatBoostClassifier()\n",
    "model7.load_model(\"./output/catboost_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LGBM\n",
    "\"\"\"\n",
    "\n",
    "model8 = lgb.Booster(model_file=\"./output/lightgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinput data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Files: 100%|██████████| 3/3 [00:00<00:00, 768.23it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import just the testing dataset\n",
    "\"\"\"\n",
    "\n",
    "def read_images_from_hdf5(file_path):\n",
    "    images = {}\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            for key in tqdm(file.keys(), desc=\"Reading Files\"):\n",
    "                try:\n",
    "                    image_data = file[key][()]\n",
    "                    image = Image.open(io.BytesIO(image_data))\n",
    "                    images[key] = image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error! from {key}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occured while reading files : {e}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "test_images = read_images_from_hdf5(TEST_HDF)\n",
    "test_metadata = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import test image dataloaders for CNN evaluation\n",
    "\"\"\"\n",
    "\n",
    "def remove_hair(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    blackhat = cv2.morphologyEx(gray,cv2.MORPH_BLACKHAT,kernel)\n",
    "\n",
    "    _, thresh = cv2.threshold(blackhat, 10 ,255, cv2.THRESH_BINARY)\n",
    "    inpainted_image = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "    return inpainted_image\n",
    "\n",
    "\n",
    "class ISIC_2024(Dataset):\n",
    "    def __init__(self,pil_images,metadata,transform=None,test=False):\n",
    "        self.pil_images = pil_images\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "        self.test= test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    # This function from https://www.kaggle.com/competitions/isic-2024-challenge/discussion/519735\n",
    "    def remove_hair(image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "        blackhat = cv2.morphologyEx(gray,cv2.MORPH_BLACKHAT,kernel)\n",
    "\n",
    "        _, thresh = cv2.threshold(blackhat, 10 ,255, cv2.THRESH_BINARY)\n",
    "        inpainted_image = cv2.inpaint(image, thresh, 1, cv2.INPAINT_TELEA)\n",
    "        return inpainted_image\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        isic_id = self.metadata.iloc[idx,0]\n",
    "        cleaned_image = remove_hair(np.array(self.pil_images[isic_id]))\n",
    "        image = Image.fromarray(cleaned_image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.test:\n",
    "            return image, isic_id\n",
    "        label = self.metadata.iloc[idx,-1]\n",
    "        return image,label,isic_id\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "     transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # commonly used mean and std calculated from ImageNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ISIC_2024(test_images, test_metadata, transform = test_transforms, test = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0015657', 'ISIC_0015729', 'ISIC_0015740']\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    # Check the length of the batch\n",
    "    \n",
    "    # Adjust based on what your dataset returns\n",
    "    if len(batch) == 2:\n",
    "        images, ids = batch\n",
    "    elif len(batch) == 3:\n",
    "        images, ids, labels = batch  # Assuming the third element is the label\n",
    "    # Add more conditions if necessary\n",
    "    \n",
    "    # Use the images and ids as needed\n",
    "    print(ids)\n",
    "    break  # Just to check one iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISIC_0015657', 'ISIC_0015729', 'ISIC_0015740']\n"
     ]
    }
   ],
   "source": [
    "for images, ids in test_loader:\n",
    "    print(ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan6600_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
